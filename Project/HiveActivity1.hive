hive> CREATE TABLE episodeIV ( name STRING , line STRING)
    > ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t'
    > TBLPROPERTIES ("skip.header.line.count"="2");
OK
Time taken: 8.934 seconds
hive> show tables;
OK
episodeiv
files
word_counts
Time taken: 0.577 seconds, Fetched: 3 row(s)
hive> LOAD DATA LOCAL INPATH '/root/episode4.txt' INTO TABLE episodeIV;
Loading data to table default.episodeiv
OK
Time taken: 16.938 seconds
hive> SELECT name,COUNT(name) AS no_of_lines from episodeIV GROUP BY name ORDER BY no_of_lines;
Query ID = root_20221122181606_7c1779a8-84eb-4c88-89b2-312fd98b0e04
Total jobs = 2
Launching Job 1 out of 2
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1669135567576_0003, Tracking URL = http://f5350e5fcdfc:8088/proxy/application_1669135567576_0003/
Kill Command = /usr/local/hadoop/bin/mapred job  -kill job_1669135567576_0003
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2022-11-22 18:19:11,441 Stage-1 map = 0%,  reduce = 0%
2022-11-22 18:20:11,829 Stage-1 map = 0%,  reduce = 0%
2022-11-22 18:21:06,405 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 134.6 sec
2022-11-22 18:21:49,674 Stage-1 map = 100%,  reduce = 67%, Cumulative CPU 141.5 sec
2022-11-22 18:21:53,421 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 149.84 sec
MapReduce Total cumulative CPU time: 2 minutes 29 seconds 840 msec
Ended Job = job_1669135567576_0003
Launching Job 2 out of 2
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1669135567576_0004, Tracking URL = http://f5350e5fcdfc:8088/proxy/application_1669135567576_0004/
Kill Command = /usr/local/hadoop/bin/mapred job  -kill job_1669135567576_0004
Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1
2022-11-22 18:22:34,310 Stage-2 map = 0%,  reduce = 0%
2022-11-22 18:23:38,223 Stage-2 map = 0%,  reduce = 0%, Cumulative CPU 39.54 sec
2022-11-22 18:23:44,709 Stage-2 map = 67%,  reduce = 0%, Cumulative CPU 75.04 sec
2022-11-22 18:23:58,907 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 86.38 sec
2022-11-22 18:24:28,128 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 97.59 sec
MapReduce Total cumulative CPU time: 1 minutes 37 seconds 590 msec
Ended Job = job_1669135567576_0004
MapReduce Jobs Launched:
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 149.84 sec   HDFS Read: 79766 HDFS Write: 2015 SUCCESS
Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 97.59 sec   HDFS Read: 9535 HDFS Write: 1753 SUCCESS
Total MapReduce CPU Time Spent: 4 minutes 7 seconds 430 msec
OK
ASTRO-OFFICER   1
WINGMAN'S VOICE 1
WINGMAN 1
VOICE OVER DEATH STAR INTERCOM  1
TROOPER VOICE   1
TECHNICIAN      1
SECOND OFFICER  1
RED TEN'S VOICE 1
RED SEVEN       1
RED NINE'S VOICE        1
RED NINE        1
RED LEADER'S VOICE      1
RED ELEVEN      1
REBEL OFFICER   1
PORKINS 1
OFFICER CASS    1
MAN'S VOICE     1
LUKE'S VOICE    1
WOMAN   1
HAN'S VOICE     1
FIRST OFFICER   1
DEAK    1
CREATURE        1
CONTROL OFFICER 1
CHIEF PILOT     1
CAPTAIN 1
BERU    1
BASE VOICE      1
GOLD TWO        2
WILLARD 2
GANTRY OFFICER  2
CHIEF   2
FIXER   2
IMPERIAL OFFICER        2
CAMIE   2
SECOND TROOPER  3
BARTENDER       3
COMMANDER       3
VOICE   3
MASSASSI INTERCOM VOICE 3
TAGGE   4
MOTTI   4
HUMAN   4
DODONNA 6
GREEDO  6
INTERCOM VOICE  6
FIRST TROOPER   6
JABBA   6
AUNT BERU       6
BEN'S VOICE     6
DEATH STAR INTERCOM VOICE       6
RED TEN 7
GOLD FIVE       7
OFFICER 11
WEDGE   14
GOLD LEADER     14
TROOPER 19
OWEN    25
TARKIN  28
BIGGS   34
RED LEADER      36
VADER   41
LEIA    57
BEN     76
THREEPIO        119
HAN     152
LUKE    253
Time taken: 507.568 seconds, Fetched: 67 row(s)
hive> INSERT OVERWRITE DIRECTORY '/user/root/outputs/export' ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t'
    > SELECT name,COUNT(name) AS no_of_lines from episodeIV GROUP BY name ORDER BY no_of_lines;
Query ID = root_20221122182612_b8408ed0-3115-4b99-a41c-4c75b0753073
Total jobs = 2
Launching Job 1 out of 2
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1669135567576_0005, Tracking URL = http://f5350e5fcdfc:8088/proxy/application_1669135567576_0005/
Kill Command = /usr/local/hadoop/bin/mapred job  -kill job_1669135567576_0005
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2022-11-22 18:27:05,116 Stage-1 map = 0%,  reduce = 0%
2022-11-22 18:28:37,002 Stage-1 map = 0%,  reduce = 0%
2022-11-22 18:29:08,666 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 125.45 sec
2022-11-22 18:29:36,759 Stage-1 map = 100%,  reduce = 68%, Cumulative CPU 144.14 sec
2022-11-22 18:29:38,855 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 148.79 sec
MapReduce Total cumulative CPU time: 2 minutes 28 seconds 790 msec
Ended Job = job_1669135567576_0005
Launching Job 2 out of 2
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1669135567576_0006, Tracking URL = http://f5350e5fcdfc:8088/proxy/application_1669135567576_0006/
Kill Command = /usr/local/hadoop/bin/mapred job  -kill job_1669135567576_0006
Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1
2022-11-22 18:30:33,162 Stage-2 map = 0%,  reduce = 0%
2022-11-22 18:30:44,364 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 4.68 sec
2022-11-22 18:30:59,304 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 12.51 sec
MapReduce Total cumulative CPU time: 12 seconds 510 msec
Ended Job = job_1669135567576_0006
Moving data to directory /user/root/outputs/export
MapReduce Jobs Launched:
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 148.79 sec   HDFS Read: 79878 HDFS Write: 2015 SUCCESS
Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 12.51 sec   HDFS Read: 9129 HDFS Write: 862 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 41 seconds 300 msec
OK
Time taken: 298.976 seconds